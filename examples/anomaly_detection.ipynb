{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bita0277b408a0544aa93096ac794eda4ce",
   "display_name": "Python 3.7.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar todas las librer√≠as necesarias.\n",
    "import csv\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from htm.bindings.sdr import SDR, Metrics\n",
    "from htm.encoders.rdse import RDSE, RDSE_Parameters\n",
    "from htm.encoders.date import DateEncoder\n",
    "from htm.bindings.algorithms import SpatialPooler\n",
    "from htm.bindings.algorithms import TemporalMemory\n",
    "from htm.algorithms.anomaly_likelihood import AnomalyLikelihood\n",
    "from htm.bindings.algorithms import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo\n",
    "_INPUT_FILE_PATH = os.path.join(\"/home/capri/thesis_msc/docs/files\", \"gymdata.csv\")\n",
    "\n",
    "# Default parameters in HTM\n",
    "default_parameters = {\n",
    "# there are 2 (3) encoders: \"value\" (RDSE) & \"time\" (DateTime weekend, timeOfDay)\n",
    " 'enc': {\n",
    "      \"value\" :\n",
    "         {'resolution': 0.88, 'size': 700, 'sparsity': 0.02},\n",
    "      \"time\": \n",
    "         {'timeOfDay': (30, 1)} #, 'weekend': 21}\n",
    " },\n",
    " 'predictor': {'sdrc_alpha': 0.1},\n",
    " 'sp': {'boostStrength': 3.0,\n",
    "        'columnCount': 1638,\n",
    "        'localAreaDensity': 0.04395604395604396,\n",
    "        'potentialPct': 0.85,\n",
    "        'synPermActiveInc': 0.04,\n",
    "        'synPermConnected': 0.13999999999999999,\n",
    "        'synPermInactiveDec': 0.006},\n",
    " 'tm': {'activationThreshold': 17,\n",
    "        'cellsPerColumn': 13,\n",
    "        'initialPerm': 0.21,\n",
    "        'maxSegmentsPerCell': 128,\n",
    "        'maxSynapsesPerSegment': 64,\n",
    "        'minThreshold': 10,\n",
    "        'newSynapseCount': 32,\n",
    "        'permanenceDec': 0.1,\n",
    "        'permanenceInc': 0.1},\n",
    " 'anomaly': {\n",
    "   'likelihood': \n",
    "       {'probationaryPct': 0.1,\n",
    "        'reestimationPeriod': 100}\n",
    " }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "13800.265"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Read the data file\n",
    "data = pd.read_excel('../docs/files/DL_Traffic_202006.xlsx', index_col=0)\n",
    "float(data.iloc[0])"
   ]
  },
  {
   "source": [
    "# Make the encoders\n",
    "dateEncoder = DateEncoder(timeOfDay= default_parameters[\"enc\"][\"time\"][\"timeOfDay\"])\n",
    "scalarEncoderParams             = RDSE_Parameters()\n",
    "scalarEncoderParams.size        = default_parameters[\"enc\"][\"value\"][\"size\"]\n",
    "scalarEncoderParams.sparsity    = default_parameters[\"enc\"][\"value\"][\"sparsity\"]\n",
    "scalarEncoderParams.resolution  = default_parameters[\"enc\"][\"value\"][\"resolution\"]\n",
    "scalarEncoder = RDSE( scalarEncoderParams )\n",
    "encodingWidth = (dateEncoder.size + scalarEncoder.size)\n",
    "enc_info = Metrics( [encodingWidth], 999999999)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the HTM\n",
    "spParams = default_parameters[\"sp\"]\n",
    "sp = SpatialPooler(\n",
    "    inputDimensions            = (encodingWidth,),\n",
    "    columnDimensions           = (spParams[\"columnCount\"],),\n",
    "    potentialPct               = spParams[\"potentialPct\"],\n",
    "    potentialRadius            = encodingWidth,\n",
    "    globalInhibition           = True,\n",
    "    localAreaDensity           = spParams[\"localAreaDensity\"],\n",
    "    synPermInactiveDec         = spParams[\"synPermInactiveDec\"],\n",
    "    synPermActiveInc           = spParams[\"synPermActiveInc\"],\n",
    "    synPermConnected           = spParams[\"synPermConnected\"],\n",
    "    boostStrength              = spParams[\"boostStrength\"],\n",
    "    wrapAround                 = True\n",
    ")\n",
    "sp_info = Metrics( sp.getColumnDimensions(), 999999999 )\n",
    "\n",
    "# Temporal Memory Parameters\n",
    "tmParams = default_parameters[\"tm\"]\n",
    "tm = TemporalMemory(\n",
    "    columnDimensions          = (spParams[\"columnCount\"],),\n",
    "    cellsPerColumn            = tmParams[\"cellsPerColumn\"],\n",
    "    activationThreshold       = tmParams[\"activationThreshold\"],\n",
    "    initialPermanence         = tmParams[\"initialPerm\"],\n",
    "    connectedPermanence       = spParams[\"synPermConnected\"],\n",
    "    minThreshold              = tmParams[\"minThreshold\"],\n",
    "    maxNewSynapseCount        = tmParams[\"newSynapseCount\"],\n",
    "    permanenceIncrement       = tmParams[\"permanenceInc\"],\n",
    "    permanenceDecrement       = tmParams[\"permanenceDec\"],\n",
    "    predictedSegmentDecrement = 0.0,\n",
    "    maxSegmentsPerCell        = tmParams[\"maxSegmentsPerCell\"],\n",
    "    maxSynapsesPerSegment     = tmParams[\"maxSynapsesPerSegment\"]\n",
    ")\n",
    "tm_info = Metrics( [tm.numberOfCells()], 999999999 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Likelihood\n",
    "anParams = default_parameters[\"anomaly\"][\"likelihood\"]\n",
    "probationaryPeriod = int(math.floor(float(anParams[\"probationaryPct\"])*len(data)))\n",
    "learningPeriod     = int(math.floor(probationaryPeriod / 2.0))\n",
    "anomaly_history    = AnomalyLikelihood(learningPeriod= learningPeriod,\n",
    "                                    estimationSamples= probationaryPeriod - learningPeriod,\n",
    "                                    reestimationPeriod= anParams[\"reestimationPeriod\"])\n",
    "\n",
    "predictor = Predictor( steps=[1, 5], alpha=default_parameters[\"predictor\"]['sdrc_alpha'] )\n",
    "predictor_resolution = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-203878b03571>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# print(range(len(data)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Convert date string into Python date object. # 2020-06-01 00:15:00\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Iterate through every datum in dataset\n",
    "inputs      = []\n",
    "anomaly     = []\n",
    "anomalyProb = []\n",
    "predictions = {1: [], 5: []}\n",
    "# print(range(len(data)))\n",
    "for count in range(len(data)):\n",
    "\n",
    "    # Convert date string into Python date object. # 2020-06-01 00:15:00\n",
    "    dateString = datetime.datetime.strptime(str(data.index[count]), \"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Convert data value string into float.\n",
    "    consumption = float(data.iloc[count])\n",
    "    inputs.append( consumption )\n",
    "    print(count)\n",
    "\n",
    "    # Call the encoders to create bit representations for each value.  These are SDR objects.\n",
    "    dateBits        = dateEncoder.encode(dateString)\n",
    "    consumptionBits = scalarEncoder.encode(consumption)\n",
    "\n",
    "    # Concatenate all these encodings into one large encoding for Spatial Pooling.\n",
    "    encoding = SDR( encodingWidth ).concatenate([consumptionBits, dateBits])\n",
    "    enc_info.addData( encoding )\n",
    "\n",
    "    # Create an SDR to represent active columns, This will be populated by the\n",
    "    # compute method below. It must have the same dimensions as the Spatial Pooler.\n",
    "    activeColumns = SDR( sp.getColumnDimensions() )\n",
    "\n",
    "    # Execute Spatial Pooling algorithm over input space.\n",
    "    sp.compute(encoding, True, activeColumns)\n",
    "    sp_info.addData( activeColumns )\n",
    "\n",
    "    # Execute Temporal Memory algorithm over active mini-columns.\n",
    "    tm.compute(activeColumns, learn=True)\n",
    "    tm_info.addData( tm.getActiveCells().flatten() )\n",
    "\n",
    "    # Predict what will happen, and then train the predictor based on what just happened.\n",
    "    pdf = predictor.infer( tm.getActiveCells() )\n",
    "    for n in (1, 5):\n",
    "        if pdf[n]:\n",
    "            predictions[n].append( np.argmax( pdf[n] ) * predictor_resolution )\n",
    "        else:\n",
    "            predictions[n].append(float('nan'))\n",
    "\n",
    "    anomalyLikelihood = anomaly_history.anomalyProbability( consumption, tm.anomaly )\n",
    "    anomaly.append( tm.anomaly )\n",
    "    anomalyProb.append( anomalyLikelihood )\n",
    "\n",
    "    predictor.learn(count, tm.getActiveCells(), int(consumption / predictor_resolution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2d1aa2a20fd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Shift the predictions so that they are aligned with the input they predict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mpred_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# Print information & Statistics about HTM state.\n",
    "\n",
    "# Shift the predictions so that they are aligned with the input they predict.\n",
    "for n_steps, pred_list in predictions.items():\n",
    "    for x in range(n_steps):\n",
    "        pred_list.insert(0, float('nan'))\n",
    "        pred_list.pop()\n",
    "\n",
    "# Calculate the predictive accuracy, Root-Mean-Squared\n",
    "accuracy         = {1: 0, 5: 0}\n",
    "accuracy_samples = {1: 0, 5: 0}\n",
    "\n",
    "for idx, inp in enumerate(inputs):\n",
    "    for n in predictions: # For each [N]umber of time steps ahead which was predicted.\n",
    "        val = predictions[n][ idx ]\n",
    "        if not math.isnan(val):\n",
    "            accuracy[n] += (inp - val) ** 2\n",
    "            accuracy_samples[n] += 1\n",
    "for n in sorted(predictions):\n",
    "    accuracy[n] = (accuracy[n] / accuracy_samples[n]) ** .5\n",
    "    print(\"Predictive Error (RMS)\", n, \"steps ahead:\", accuracy[n])\n",
    "\n",
    "# Show info about the anomaly (mean & std)\n",
    "print(\"Anomaly Mean\", np.mean(anomaly))\n",
    "print(\"Anomaly Std \", np.std(anomaly))\n",
    "\n",
    "# Plot the Predictions and Anomalies.\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.title(\"Predictions\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Power Consumption\")\n",
    "plt.plot(np.arange(len(inputs)), inputs, 'red',\n",
    "            np.arange(len(inputs)), predictions[1], 'blue',\n",
    "            np.arange(len(inputs)), predictions[5], 'green',)\n",
    "plt.legend(labels=('Input', '1 Step Prediction, Shifted 1 step', '5 Step Prediction, Shifted 5 steps'))\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.title(\"Anomaly Score\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Power Consumption\")\n",
    "inputs = np.array(inputs) / max(inputs)\n",
    "plt.plot(np.arange(len(inputs)), inputs, 'red',\n",
    "            np.arange(len(inputs)), anomaly, 'blue',)\n",
    "plt.legend(labels=('Input', 'Anomaly Score'))\n",
    "plt.show()\n",
    "\n",
    "print(accuracy[5])"
   ]
  }
 ]
}